import paho.mqtt.client as mqtt
import time
import os
from picamera2 import Picamera2
from groq import Groq
import requests
from gtts import gTTS
import base64
import json
import speech_recognition as sr
import tempfile
import subprocess

# -------------------------------
# CONFIGURACI√ìN MQTT & SISTEMA
# -------------------------------
BROKER_IP = "127.0.0.1"
TOPIC = "robot/distancia"
UMBRAL_DISTANCIA = 45.0

# -------------------------------
# API KEYS
# -------------------------------
GROQ_API_KEY = "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"
GEMINI_API_KEY = "AIzaSyDSZMkphVRVJenyacVR2USWJl1IzPiGCmY"

GEMINI_API_URL = (
    "https://generativelanguage.googleapis.com/v1beta/models/"
    "gemini-2.5-flash-preview-09-2025:generateContent"
    f"?key={GEMINI_API_KEY}"
)

# -------------------------------
# CLIENTE GROQ
# -------------------------------
try:
    groq_client = Groq(api_key=GROQ_API_KEY)
except Exception as e:
    print("‚ùå Error: No se pudo inicializar Groq:", e)
    groq_client = None

# -------------------------------
# C√ÅMARA (Picamera2)
# -------------------------------
picam2 = None
try:
    picam2 = Picamera2()
    config = picam2.create_still_configuration(main={"size": (640, 480)})
    picam2.configure(config)
    picam2.start()
    print("üì∏ C√°mara lista.")
    time.sleep(2)
except Exception as e:
    print(f"‚ùå Error iniciando c√°mara: {e}")

# -------------------------------
# UTILIDADES
# -------------------------------
def image_to_base64(filepath):
    try:
        with open(filepath, "rb") as f:
            return base64.b64encode(f.read()).decode("utf-8")
    except Exception:
        return None


def detectar_emocion_con_ia(image_path):
    """Env√≠a la imagen a Gemini y devuelve la emoci√≥n (una palabra)."""
    print("ü§ñ Enviando imagen a Gemini...")
    base64_image = image_to_base64(image_path)
    if not base64_image:
        return "desconocida"

    payload = {
        "contents": [
            {
                "parts": [
                    {"text": "Analiza la emoci√≥n principal de la persona. Responde con una sola palabra."},
                    {
                        "inlineData": {
                            "mimeType": "image/jpeg",
                            "data": base64_image
                        }
                    }
                ]
            }
        ]
    }

    try:
        r = requests.post(GEMINI_API_URL, json=payload, timeout=15)
        r.raise_for_status()
        data = r.json()
        emocion = data["candidates"][0]["content"]["parts"][0]["text"]
        return emocion.strip().lower()
    except Exception as e:
        print(f"‚ùå Error con Gemini: {e}")
        return "desconocida"


def generar_respuesta_groq(emocion, contexto_usuario=None):
    """Genera una respuesta corta y emp√°tica desde Groq, dado la emoci√≥n y contexto opcional."""
    if not groq_client:
        return "Perd√≥n, ahora no puedo pensar."

    prompt = f"Eres un robot de apoyo emocional. Da una respuesta breve y c√°lida para alguien que muestra '{emocion}'. M√°ximo 30 palabras. Espa√±ol."
    if contexto_usuario:
        prompt += f" Adem√°s, la persona dijo: '{contexto_usuario}'. Responde de forma emp√°tica."

    try:
        completion = groq_client.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model="llama-3.1-8b-instant",
            temperature=0.7
        )
        return completion.choices[0].message.content.strip()
    except Exception as e:
        print("‚ùå Error Groq:", e)
        return "Lo siento, tuve un problema para pensar."


# -------------------------------
# AUDIO: TTS y reproducci√≥n confiable con Bluetooth
# -------------------------------
def hablar_mensaje(texto):
    """
    Convierte texto a voz con gTTS y reproduce usando paplay (PipeWire respeta sink Bluetooth).
    """
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as f:
            ruta_mp3 = f.name
        tts = gTTS(text=texto, lang='es')
        tts.save(ruta_mp3)

        # Convertir mp3 a wav para paplay
        ruta_wav = ruta_mp3.replace(".mp3", ".wav")
        subprocess.run(["ffmpeg", "-y", "-i", ruta_mp3, ruta_wav],
                       stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

        # Reproducir con paplay
        subprocess.run(["paplay", ruta_wav])

    except Exception as e:
        print("‚ùå Error al reproducir audio:", e)
    finally:
        for f in [ruta_mp3, ruta_wav]:
            if os.path.exists(f):
                os.remove(f)


# -------------------------------
# AUDIO: Escuchar con SpeechRecognition
# -------------------------------
def escuchar_y_transcribir(timeout=8, phrase_time_limit=8):
    """
    Escucha por el micr√≥fono y devuelve texto.
    Devuelve "" si no entiende o hay error.
    """
    recognizer = sr.Recognizer()
    try:
        with sr.Microphone(device_index=2) as source:
            recognizer.adjust_for_ambient_noise(source, duration=0.8)
            print("üé§ Escuchando... (habla ahora)")
            try:
                audio = recognizer.listen(source, timeout=timeout, phrase_time_limit=phrase_time_limit)
            except sr.WaitTimeoutError:
                print("‚ö†Ô∏è Timeout: no se detect√≥ voz.")
                return ""
    except Exception as e:
        print("‚ùå Error accediendo al micr√≥fono:", e)
        return ""

    try:
        texto = recognizer.recognize_google(audio, language="es-PE")
        print("üó£Ô∏è Detectado (STT):", texto)
        return texto
    except sr.UnknownValueError:
        print("‚ö†Ô∏è No entend√≠ (STT).")
        return ""
    except sr.RequestError as e:
        print("‚ùå Error servicio STT:", e)
        return ""


# -------------------------------
# FLUJO DE INTERACCI√ìN
# -------------------------------
def conversacion_continua(inicio_saludo):
    frases_finales = [
        "gracias estoy bien",
        "estoy bien gracias",
        "ya estoy bien",
        "todo bien gracias"
    ]

    hablar_mensaje(inicio_saludo)
    time.sleep(0.4)

    hablar_mensaje("Si quieres, podemos conversar. Dime lo que sientes o di 'gracias estoy bien' para terminar.")
    time.sleep(0.3)

    while True:
        texto_usuario = escuchar_y_transcribir(timeout=8, phrase_time_limit=10)
        if not texto_usuario:
            hablar_mensaje("No te escuch√©. ¬øQuieres intentarlo otra vez? O si deseas terminar, di 'gracias estoy bien'.")
            continue

        normalizado = texto_usuario.strip().lower()

        # üö® DETECCI√ìN DE FIN DE CONVERSACI√ìN Y APAGADO üö®
        if any(frase in normalizado for frase in frases_finales):
            hablar_mensaje("Me alegra que est√©s bien. Descansar√© por ahora.")
            print("üõë Apagando robot por frase de cierre...")
            os._exit(0)   # <-- Apaga TODO el robot
            return

        respuesta_ia = generar_respuesta_groq("conversaci√≥n", contexto_usuario=texto_usuario)
        print("ü§ñ IA responde:", respuesta_ia)
        hablar_mensaje(respuesta_ia)

# -------------------------------
# DETECCI√ìN DE EMOCI√ìN
# -------------------------------
def deteccion_emocion(distancia):
    ruta_imagen = "/tmp/rostro_capturado.jpg"
    print(f"\n--- PERSONA DETECTADA A {distancia:.1f} cm ---")

    try:
        if picam2:
            picam2.capture_file(ruta_imagen)
            print("üì∏ Imagen capturada.")
        else:
            print("‚ö†Ô∏è picam2 no inicializada, no se toma foto.")
    except Exception as e:
        print("‚ùå Error al capturar imagen:", e)

    emocion = detectar_emocion_con_ia(ruta_imagen)
    print(f"üòä Emoci√≥n detectada: {emocion}")

    respuesta = generar_respuesta_groq(emocion)
    print(f"üí¨ Respuesta creada: {respuesta}")

    hablar_mensaje(respuesta)
    conversacion_continua("Si quieres, podemos hablar ahora mismo.")


# -------------------------------
# MQTT: callbacks
# -------------------------------
def on_message(client, userdata, msg):
    try:
        distancia = float(msg.payload.decode())
        if 0 < distancia < UMBRAL_DISTANCIA:
            print(f"üö® Persona cerca: {distancia} cm")
            deteccion_emocion(distancia)
        else:
            print(f"Distancia: {distancia} cm")
    except Exception as e:
        print("‚ö†Ô∏è Mensaje inv√°lido:", e)


def on_connect(client, userdata, flags, rc):
    if rc == 0:
        print("üì° Conectado a MQTT")
        client.subscribe(TOPIC)
    else:
        print("‚ùå Error MQTT, rc=", rc)


# -------------------------------
# MAIN
# -------------------------------
if __name__ == "__main__":
    try:
        client = mqtt.Client(client_id="Pi5_Robot_Ansiedad", protocol=mqtt.MQTTv311)
        client.on_connect = on_connect
        client.on_message = on_message

        print("üîå Conectando al broker MQTT...")
        client.connect(BROKER_IP, 1883, 60)
        client.loop_forever()

    except KeyboardInterrupt:
        print("\nüõë Programa detenido por el usuario (Ctrl+C).")
    except Exception as e:
        print("‚ùå Error cr√≠tico:", e)


